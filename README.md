# Neural Style Transfer in telegram bot

В данном репозитории представлена интегрированное в бота средство переноса стиля. Перенос стиля осуществляется посредством работы различных нейронных сетей. В зависимости от поставленных задач используется определенная архитектура.

## NST PART 
### AdaIN 

Архитектура, описанная впервые в 2017 в статье , представляет собой 

В собственной реализации я решил изменить mse loss для стиля на l1 loss руководствуясь следующей логикой: 
MSE loss будет сильнее штрафовать сеть за несоответсвие каких то отдельных пикселей, а самое значение функции потерь будет сильно выше. При правильно подобранных для соответствующего датасета гиперпараметров 
Также по аналогии с GAN добавить в архитектуру Гауссовский шум. Обьективно сложно оценить , но автор считает нововведения  

Note: В файле models/nst_model.py представлена обрезанная версия программы, созданная исключительно под инференс. В программе отсутвуют функции: обаботки датасета для обучения, самого обучения и его контроля. 

### MUNIT
В разработке

## BOT PART

Весь код представлен в файле telegram_bot.py. Бот построен на асинхронной системе с помощью фреймворка aiogram. Также приложение развернуто на Веб-хостинге Heroku с помощью webhook стратегии во избежание засыпания после инактива. Для запуска бота созданы два файла requirements.txt и Procfile с версиями библиотек необходимых для корректной работы и служебная информация о запуске для самого хостинга соответсвенно.

###requiremets.txt
    aiogram==2.19
    Pillow==7.1.2
    https://download.pytorch.org/whl/cpu/torch-1.10.0%2Bcpu-cp37-cp37m-linux_x86_64.whl
    https://download.pytorch.org/whl/cpu/torchvision-0.11.1%2Bcpu-cp37-cp37m-linux_x86_64.whl

В связи с ограничением предоставляемой памяти в 500МБ и бесмысленности установки CUDA версий на CPU-only сервис, версии для pytorch==1.10.0 и torchvision==1.10.1 представлены ссылкам на соответсвующие ресурсы для загрузки. Конечный размер сборки составляет 315 МБ.

###Procfile
   web: python3 telegram_bot.py

## Планируемые обновления 
